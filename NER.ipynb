{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammedterry/NLP_for_ML/blob/master/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINfboLPqcO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_document = '''Baidu's Apollo Project is one of the world's leading autonomous driving and AI programs, with one of the largest partner ecosystems and over 100 global partners as of 2018, including BYD, Dongfeng, Microsoft, Intel, Nvidia, Daimler AG, ZTE, Grab, Ford, Hyundai and Honda.'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btx1denTqF1_",
        "colab_type": "text"
      },
      "source": [
        "# GATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvmXB7UKqIeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1626
        },
        "outputId": "2b7513f8-9d7a-4ab8-937e-75233c206956"
      },
      "source": [
        "import requests\n",
        "url = \"https://cloud-api.gate.ac.uk/process-document/annie-named-entity-recognizer\"\n",
        "headers = {'Content-Type': 'text/plain'}\n",
        "response = requests.post(url, data=example_document, headers=headers).json()\n",
        "\n",
        "import json\n",
        "print(json.dumps(response, indent=2))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"text\": \"Baidu's Apollo Project is one of the world's leading autonomous driving and AI programs, with one of the largest partner ecosystems and over 100 global partners as of 2018, including BYD, Dongfeng, Microsoft, Intel, Nvidia, Daimler AG, ZTE, Grab, Ford, Hyundai and Honda.\",\n",
            "  \"entities\": {\n",
            "    \"Date\": [\n",
            "      {\n",
            "        \"indices\": [\n",
            "          167,\n",
            "          171\n",
            "        ],\n",
            "        \"kind\": \"date\",\n",
            "        \"rule\": \"TempYear2\",\n",
            "        \"ruleFinal\": \"YearOnlyFinal\"\n",
            "      }\n",
            "    ],\n",
            "    \"Location\": [\n",
            "      {\n",
            "        \"indices\": [\n",
            "          247,\n",
            "          251\n",
            "        ],\n",
            "        \"locType\": \"city\",\n",
            "        \"rule\": \"Location1\",\n",
            "        \"ruleFinal\": \"LocFinal\"\n",
            "      }\n",
            "    ],\n",
            "    \"Organization\": [\n",
            "      {\n",
            "        \"indices\": [\n",
            "          8,\n",
            "          22\n",
            "        ],\n",
            "        \"orgType\": \"unknown\",\n",
            "        \"rule\": \"OrgXBase\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      },\n",
            "      {\n",
            "        \"indices\": [\n",
            "          198,\n",
            "          207\n",
            "        ],\n",
            "        \"orgType\": \"company\",\n",
            "        \"rule\": \"GazOrganization\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      },\n",
            "      {\n",
            "        \"indices\": [\n",
            "          209,\n",
            "          214\n",
            "        ],\n",
            "        \"orgType\": \"company\",\n",
            "        \"rule\": \"GazOrganization\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      },\n",
            "      {\n",
            "        \"indices\": [\n",
            "          216,\n",
            "          222\n",
            "        ],\n",
            "        \"orgType\": \"company\",\n",
            "        \"rule\": \"GazOrganization\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      },\n",
            "      {\n",
            "        \"indices\": [\n",
            "          224,\n",
            "          234\n",
            "        ],\n",
            "        \"orgType\": \"company\",\n",
            "        \"rule\": \"GazOrganization\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      },\n",
            "      {\n",
            "        \"indices\": [\n",
            "          253,\n",
            "          260\n",
            "        ],\n",
            "        \"orgType\": \"company\",\n",
            "        \"rule\": \"GazOrganization\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      },\n",
            "      {\n",
            "        \"indices\": [\n",
            "          265,\n",
            "          270\n",
            "        ],\n",
            "        \"orgType\": \"company\",\n",
            "        \"rule\": \"GazOrganization\",\n",
            "        \"ruleFinal\": \"OrgFinal\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj_XZJgCqfbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gate_ner(sentence):\n",
        "  import requests\n",
        "  return [(sentence[entity[\"indices\"][0]:entity[\"indices\"][1]] + f\" ({entity['gender']})\",entity_type) if entity_type == \"Person\" and \"gender\" in entity else (sentence[entity[\"indices\"][0]:entity[\"indices\"][1]],entity_type)  for entity_type,entities in requests.post(\"https://cloud-api.gate.ac.uk/process-document/annie-named-entity-recognizer\", data=sentence, headers={'Content-Type': 'text/plain'}).json()[\"entities\"].items() for entity in entities]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M10blkrErQ28",
        "colab_type": "code",
        "outputId": "ba8b989c-024e-43ca-f390-6ebc6b73293c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "gate_ner(example_document)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2018', 'Date'),\n",
              " ('Ford', 'Location'),\n",
              " ('Apollo Project', 'Organization'),\n",
              " ('Microsoft', 'Organization'),\n",
              " ('Intel', 'Organization'),\n",
              " ('Nvidia', 'Organization'),\n",
              " ('Daimler AG', 'Organization'),\n",
              " ('Hyundai', 'Organization'),\n",
              " ('Honda', 'Organization')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdHi9MLEt6OB",
        "colab_type": "text"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLtIbPYJuAfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "42d48ce4-ac66-4254-e654-5981d7d666cf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r0uSb7LqwKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_ner(document):\n",
        "  return {(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfbUR4QueDe",
        "colab_type": "code",
        "outputId": "e22ae861-0874-4b42-d49b-90211e523954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "nltk_ner(example_document)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('AI', 'ORGANIZATION'),\n",
              " ('Apollo Project', 'PERSON'),\n",
              " ('BYD', 'ORGANIZATION'),\n",
              " ('Baidu', 'GPE'),\n",
              " ('Daimler AG', 'PERSON'),\n",
              " ('Dongfeng', 'PERSON'),\n",
              " ('Ford', 'ORGANIZATION'),\n",
              " ('Grab', 'PERSON'),\n",
              " ('Honda', 'GPE'),\n",
              " ('Hyundai', 'PERSON'),\n",
              " ('Intel', 'ORGANIZATION'),\n",
              " ('Microsoft', 'PERSON'),\n",
              " ('Nvidia', 'GPE'),\n",
              " ('ZTE', 'ORGANIZATION')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjg7Sj3Tt8bz",
        "colab_type": "text"
      },
      "source": [
        "# Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkg1NC08xVYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -m spacy download en_core_web_lg\n",
        "import spacy\n",
        "sp_lg = spacy.load('en_core_web_lg') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghnQyFifqqeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spacy_large_ner(document):\n",
        "  return {(ent.text.strip(), ent.label_) for ent in sp_lg(document).ents}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSSFSJvVyxOX",
        "colab_type": "code",
        "outputId": "f5d42499-75d1-46dd-cbe1-5ac477d76682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "spacy_large_ner(example_document)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('2018', 'DATE'),\n",
              " ('Apollo Project', 'ORG'),\n",
              " ('BYD', 'ORG'),\n",
              " ('Baidu', 'ORG'),\n",
              " ('Daimler AG', 'ORG'),\n",
              " ('Dongfeng', 'PERSON'),\n",
              " ('Ford', 'ORG'),\n",
              " ('Honda', 'ORG'),\n",
              " ('Hyundai', 'ORG'),\n",
              " ('Intel', 'ORG'),\n",
              " ('Microsoft', 'ORG'),\n",
              " ('Nvidia', 'ORG'),\n",
              " ('ZTE', 'ORG'),\n",
              " ('over 100', 'CARDINAL')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy5wwTpCuutS",
        "colab_type": "text"
      },
      "source": [
        "# Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zkh_P6buwRq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1160
        },
        "outputId": "cec3aed4-1191-4130-a1ce-754287c1dda8"
      },
      "source": [
        "!pip3 install flair"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/54/76374f9a448ca765446502e7f2bb53c976e9c055102290fe6f8b0b038b37/flair-0.4.1.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 24.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.1.post2)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 29.2MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.2.9 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/57/90/8760eaa97c5a2f676f3f350fd43e79f8d9e4f9c42362c62f733e81e37d33/bpemb-0.2.12-py3-none-any.whl\n",
            "Requirement already satisfied: regex==2018.1.10 in /usr/local/lib/python3.6/dist-packages (from flair) (2018.1.10)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.2.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.16.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.20.3)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.10.11)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.138)\n",
            "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (41.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (1.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.138 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.138)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.138->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
            "Building wheels for collected packages: flair, segtok, mpld3, sqlitedict\n",
            "  Building wheel for flair (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/55/6b/c12cf58209b8346f653a04f37dd8f607ab0e85a26238a23420\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "Successfully built flair segtok mpld3 sqlitedict\n",
            "Installing collected packages: segtok, mpld3, sqlitedict, deprecated, pytorch-pretrained-bert, sentencepiece, bpemb, flair\n",
            "Successfully installed bpemb-0.2.12 deprecated-1.2.5 flair-0.4.1 mpld3-0.3 pytorch-pretrained-bert-0.6.2 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eEPh4_f9cXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "d525b739-b861-4f6f-87bf-6d8fde6cc8da"
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "flair_12class = SequenceTagger.load('ner-ontonotes-fast')\n",
        "flair_4class = SequenceTagger.load('ner')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:22:34,061 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.2/NER-ontoner--h256-l1-b32-%2Bcrawl%2Bnews-forward-fast%2Bnews-backward-fast--v0.2/en-ner-ontonotes-fast-v0.3.pt not found in cache, downloading to /tmp/tmpy8wumt_d\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1331337776/1331337776 [02:11<00:00, 10094955.31B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:24:47,221 copying /tmp/tmpy8wumt_d to cache at /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:24:54,910 removing temp file /tmp/tmpy8wumt_d\n",
            "2019-05-03 18:24:54,912 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-05-03 18:25:09,807 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/NER-conll03-english/en-ner-conll03-v0.4.pt not found in cache, downloading to /tmp/tmpnejixshj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 432197603/432197603 [00:47<00:00, 9149328.71B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:25:58,338 copying /tmp/tmpnejixshj to cache at /root/.flair/models/en-ner-conll03-v0.4.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:26:00,534 removing temp file /tmp/tmpnejixshj\n",
            "2019-05-03 18:26:00,536 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbzepNzhzVkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flair_ner(document, model):\n",
        "  from flair.data import Sentence\n",
        "  s = Sentence(document)\n",
        "  model.predict(s)\n",
        "  entities = s.to_dict(tag_type='ner')\n",
        "  return [(entity[\"text\"], entity[\"type\"]) for entity in entities[\"entities\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kcqsnNbz6h9",
        "colab_type": "code",
        "outputId": "8ba5cf5e-e9a5-49de-c11a-988db9af8562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "flair_ner(example_document, flair_4class)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"Baidu's Apollo Project\", 'ORG'),\n",
              " ('AI', 'ORG'),\n",
              " ('BYD, Dongfeng, Microsoft, Intel, Nvidia, Daimler AG, ZTE, Grab, Ford, Hyundai',\n",
              "  'ORG'),\n",
              " ('Honda.', 'ORG')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJsXDyy005ys",
        "colab_type": "code",
        "outputId": "15e85b5f-6940-4a6a-811e-16b9dfecaff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "flair_ner(example_document, flair_12class)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"Baidu's Apollo Project\", 'ORG'),\n",
              " ('AI', 'ORG'),\n",
              " ('over 100', 'CARDINAL'),\n",
              " ('2018,', 'DATE'),\n",
              " ('BYD, Dongfeng, Microsoft, Intel, Nvidia, Daimler', 'ORG'),\n",
              " ('Hyundai', 'ORG')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOO_vNe32Ze6",
        "colab_type": "text"
      },
      "source": [
        "# Deep Pavlov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xLK6na62sY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4511
        },
        "outputId": "79a3f792-14dd-4be4-dcfc-6f61056b4ba1"
      },
      "source": [
        "!pip3 install deeppavlov\n",
        "!python3 -m deeppavlov install ner_ontonotes\n",
        "from deeppavlov import configs, build_model\n",
        "deeppavlov_ner = build_model(configs.ner.ner_ontonotes, download=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/92/33166dcd4fd87b171d5d37a87e19fc936e97f0a7ddbe2e7c0cdae7ceabb6/deeppavlov-0.2.0-py3-none-any.whl (602kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask==1.0.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.0.2)\n",
            "Collecting numpy==1.14.5 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.2.5)\n",
            "Collecting pymorphy2-dicts-ru (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 42.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.23.1 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/eb/6ab533ea8e35e7dd159af6922ac1123d4565d89f3926ad9a6aa46530978f/pandas-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 43.1MB/s \n",
            "\u001b[?25hCollecting overrides==1.9 (from deeppavlov)\n",
            "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n",
            "Collecting fuzzywuzzy==0.16.0 (from deeppavlov)\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/36/be990a35c7e8ed9dc176c43b5699cd971cec0b6f9ef858843374171df4f2/fuzzywuzzy-0.16.0-py2.py3-none-any.whl\n",
            "Collecting requests==2.19.1 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/47/7e02164a2a3db50ed6d8a6ab1d6d60b69c4c3fdf57a284257925dfc12bda/requests-2.19.1-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 33.1MB/s \n",
            "\u001b[?25hCollecting scipy==1.1.0 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 47.0MB/s \n",
            "\u001b[?25hCollecting flask-cors==3.0.6 (from deeppavlov)\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/db/f3495569d5c3e2bdb9fb8a66c54503364abb6f35a9da2227cf5c9c50dc42/Flask_Cors-3.0.6-py2.py3-none-any.whl\n",
            "Collecting rusenttokenize==0.0.4 (from deeppavlov)\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/4c/e2aeee9cdcc266303289ad8c4acfdcf401781646bcc311ee2bf18f84d663/rusenttokenize-0.0.4-py3-none-any.whl\n",
            "Collecting pyopenssl==18.0.0 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 30.3MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.19.1 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/2d/9fbc7baa5f44bc9e88ffb7ed32721b879bfa416573e85031e16f52569bc9/scikit_learn-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 48.4MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 27.0MB/s \n",
            "\u001b[?25hCollecting Cython==0.28.5 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/8e/32b280abb0947a96cdbb8329fb2014851a21fc1d099009f946ea8a8202c3/Cython-0.28.5-cp36-cp36m-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.8.0)\n",
            "Collecting pytelegrambotapi==3.5.2 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/5a/7aab147b253f19e5ef007316f39cf693a63d5cd7f654c3805c76f6bde979/pyTelegramBotAPI-3.5.2.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 29.5MB/s \n",
            "\u001b[?25hCollecting keras==2.2.0 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 51.4MB/s \n",
            "\u001b[?25hCollecting flasgger==0.9.1 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/8735be27bebb88b0acbdc9db1d522583db10821aec3d3fb6112df0f41701/flasgger-0.9.1-py2.py3-none-any.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 55.2MB/s \n",
            "\u001b[?25hCollecting tqdm==4.23.4 (from deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->deeppavlov) (0.15.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->deeppavlov) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->deeppavlov) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->deeppavlov) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.2.5->deeppavlov) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.1->deeppavlov) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.1->deeppavlov) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.19.1->deeppavlov) (2019.3.9)\n",
            "Collecting idna<2.8,>=2.5 (from requests==2.19.1->deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.19.1->deeppavlov) (3.0.4)\n",
            "Collecting urllib3<1.24,>=1.21.1 (from requests==2.19.1->deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 59.1MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.2.1 (from pyopenssl==18.0.0->deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 45.4MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2==0.8->deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 31.3MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7 (from pymorphy2==0.8->deeppavlov)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting keras-preprocessing==1.0.1 (from keras==2.2.0->deeppavlov)\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
            "Collecting keras-applications==1.0.2 (from keras==2.2.0->deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.0->deeppavlov) (3.13)\n",
            "Requirement already satisfied: jsonschema>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from flasgger==0.9.1->deeppavlov) (2.6.0)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.6/dist-packages (from flasgger==0.9.1->deeppavlov) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask==1.0.2->deeppavlov) (1.1.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.2.1->pyopenssl==18.0.0->deeppavlov) (1.12.3)\n",
            "Collecting asn1crypto>=0.21.0 (from cryptography>=2.2.1->pyopenssl==18.0.0->deeppavlov)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.2.1->pyopenssl==18.0.0->deeppavlov) (2.19)\n",
            "Building wheels for collected packages: overrides, pytelegrambotapi\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/a0/fa/c3539fd47aa9f834230d64039c4bc620463bc7afc39b0f3f35\n",
            "Successfully built overrides pytelegrambotapi\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.13.1 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.13.1 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flair 0.4.1 has requirement tqdm>=4.26.0, but you'll have tqdm 4.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.52 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, pymorphy2-dicts-ru, pandas, overrides, fuzzywuzzy, idna, urllib3, requests, scipy, flask-cors, rusenttokenize, asn1crypto, cryptography, pyopenssl, scikit-learn, pymorphy2-dicts, dawg-python, pymorphy2, Cython, pytelegrambotapi, keras-preprocessing, keras-applications, keras, flasgger, tqdm, deeppavlov\n",
            "  Found existing installation: numpy 1.16.3\n",
            "    Uninstalling numpy-1.16.3:\n",
            "      Successfully uninstalled numpy-1.16.3\n",
            "  Found existing installation: pandas 0.24.2\n",
            "    Uninstalling pandas-0.24.2:\n",
            "      Successfully uninstalled pandas-0.24.2\n",
            "  Found existing installation: idna 2.8\n",
            "    Uninstalling idna-2.8:\n",
            "      Successfully uninstalled idna-2.8\n",
            "  Found existing installation: urllib3 1.24.2\n",
            "    Uninstalling urllib3-1.24.2:\n",
            "      Successfully uninstalled urllib3-1.24.2\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: scipy 1.2.1\n",
            "    Uninstalling scipy-1.2.1:\n",
            "      Successfully uninstalled scipy-1.2.1\n",
            "  Found existing installation: scikit-learn 0.20.3\n",
            "    Uninstalling scikit-learn-0.20.3:\n",
            "      Successfully uninstalled scikit-learn-0.20.3\n",
            "  Found existing installation: Cython 0.29.7\n",
            "    Uninstalling Cython-0.29.7:\n",
            "      Successfully uninstalled Cython-0.29.7\n",
            "  Found existing installation: Keras-Preprocessing 1.0.9\n",
            "    Uninstalling Keras-Preprocessing-1.0.9:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.9\n",
            "  Found existing installation: Keras-Applications 1.0.7\n",
            "    Uninstalling Keras-Applications-1.0.7:\n",
            "      Successfully uninstalled Keras-Applications-1.0.7\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed Cython-0.28.5 asn1crypto-0.24.0 cryptography-2.6.1 dawg-python-0.7.2 deeppavlov-0.2.0 flasgger-0.9.1 flask-cors-3.0.6 fuzzywuzzy-0.16.0 idna-2.7 keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1 numpy-1.14.5 overrides-1.9 pandas-0.23.1 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-18.0.0 pytelegrambotapi-3.5.2 requests-2.19.1 rusenttokenize-0.0.4 scikit-learn-0.19.1 scipy-1.1.0 tqdm-4.23.4 urllib3-1.23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "numpy",
                  "pandas",
                  "requests",
                  "scipy",
                  "sklearn",
                  "tqdm",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:45:42.8 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
            "Collecting gensim==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/ed/fbbb2cc3f37a39cc4ff8e5f667374478fb852b384840aa7feb9608144290/gensim-2.3.0.tar.gz (17.2MB)\n",
            "\u001b[K     |████████████████████████████████| 17.2MB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.14.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.12.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart_open>=1.2.1->gensim==2.3.0) (2.19.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart_open>=1.2.1->gensim==2.3.0) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart_open>=1.2.1->gensim==2.3.0) (1.9.138)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open>=1.2.1->gensim==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open>=1.2.1->gensim==2.3.0) (2.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open>=1.2.1->gensim==2.3.0) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open>=1.2.1->gensim==2.3.0) (1.23)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart_open>=1.2.1->gensim==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.138 in /usr/local/lib/python3.6/dist-packages (from boto3->smart_open>=1.2.1->gensim==2.3.0) (1.12.138)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart_open>=1.2.1->gensim==2.3.0) (0.9.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.138->boto3->smart_open>=1.2.1->gensim==2.3.0) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.138->boto3->smart_open>=1.2.1->gensim==2.3.0) (2.5.3)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/1f/86/63c886325bdffa379a7c91499bc9ea6317a4e4e0fc6e2ff1ce\n",
            "Successfully built gensim\n",
            "\u001b[31mERROR: flair 0.4.1 has requirement gensim>=3.4.0, but you'll have gensim 2.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flair 0.4.1 has requirement tqdm>=4.26.0, but you'll have tqdm 4.23.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-2.3.0\n",
            "Collecting tensorflow==1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K     |████████████████████████████████| 58.4MB 44.0MB/s \n",
            "\u001b[?25hCollecting setuptools<=39.1.0 (from tensorflow==1.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.33.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.12.0)\n",
            "Collecting tensorboard<1.11.0,>=1.10.0 (from tensorflow==1.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (3.7.1)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.14.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.1)\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setuptools, tensorboard, tensorflow\n",
            "  Found existing installation: setuptools 41.0.1\n",
            "    Uninstalling setuptools-41.0.1:\n",
            "      Successfully uninstalled setuptools-41.0.1\n",
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed setuptools-39.1.0 tensorboard-1.10.0 tensorflow-1.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:46:25.848 INFO in 'deeppavlov.core.data.utils'['utils'] at line 63: Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt to /root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:46:25,848 Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt to /root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "347MB [00:56, 6.14MB/s]\n",
            "2019-05-03 18:47:23.683 INFO in 'deeppavlov.core.data.utils'['utils'] at line 63: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz to /root/.deeppavlov/ner_ontonotes_v3_cpu_compatible.tar.gz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:23,683 Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz to /root/.deeppavlov/ner_ontonotes_v3_cpu_compatible.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8.13M/8.13M [00:04<00:00, 1.64MB/s]\n",
            "2019-05-03 18:47:28.648 INFO in 'deeppavlov.core.data.utils'['utils'] at line 201: Extracting /root/.deeppavlov/ner_ontonotes_v3_cpu_compatible.tar.gz archive into /root/.deeppavlov/models\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:28,648 Extracting /root/.deeppavlov/ner_ontonotes_v3_cpu_compatible.tar.gz archive into /root/.deeppavlov/models\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2019-05-03 18:47:29.935 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:29,935 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:29.943 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:29,943 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:29.950 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:47:29,950 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2019-05-03 18:47:29,954 this function is deprecated, use smart_open.open instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2019-05-03 18:48:07.348 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:48:07,348 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2019-05-03 18:48:14,219 From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:861: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "2019-05-03 18:48:14,238 From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:48:14.240 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:48:14,240 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2019-05-03 18:48:15.920 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 50: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-03 18:48:15,920 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2t_l-Lg3hYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_entities(entities):\n",
        "  ents = set()\n",
        "  for entity,next_entity in zip(entities,entities[1:] + [(\".\",\"O\")]):\n",
        "    word,tag = entity\n",
        "    if tag != \"O\":\n",
        "      ent_position, ent_type = tag.split(\"-\")\n",
        "      if ent_position == \"U\":\n",
        "        ents.add((word,ent_type))\n",
        "      else:\n",
        "        if ent_position == \"B\":\n",
        "          w = word\n",
        "        elif ent_position == \"I\":\n",
        "          w += \" \" + word\n",
        "          if next_entity[1].split(\"-\")[0] != \"I\":\n",
        "            ents.add((w,ent_type))\n",
        "  return ents\n",
        "\n",
        "def dp_ner(sentence):\n",
        "  tokens,tags = deeppavlov_ner([sentence])\n",
        "  return convert_entities([(tok,tg) for token,tag in zip(tokens,tags) for tok,tg in list(zip(token,tag)) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RozDHFQ6yHv",
        "colab_type": "code",
        "outputId": "69e8f11a-63d4-4895-9210-8d2d03ef9e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dp_ner(example_document)  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Apollo Project', 'ORG'), ('Daimler AG', 'ORG'), ('over 100', 'CARDINAL')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBqxcYavqoah",
        "colab_type": "text"
      },
      "source": [
        "# Stanford Core NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6in8psMKLMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "fcf7a65a-2d93-4fcc-e641-12a43696b0e6"
      },
      "source": [
        "!pip3 install nltk==3.2.4"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk==3.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c2/858e0708b497116ae45cf5c6b1f66984ac60729c61e49df6c1c0b808d1e4/nltk-3.2.4.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.2.4) (1.12.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/f1/5c/f667347d86a3a534ba4c0127eed4389f929916e3ec88bb461a\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: deeppavlov 0.2.0 has requirement nltk==3.2.5, but you'll have nltk 3.2.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8w7LLsyKAYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "804bf276-89d7-4956-b8c0-320b716c8c38"
      },
      "source": [
        "!wget http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip\n",
        "!unzip stanford-ner-2015-04-20.zip "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-03 18:58:03--  http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip [following]\n",
            "--2019-05-03 18:58:03--  https://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176961718 (169M) [application/zip]\n",
            "Saving to: ‘stanford-ner-2015-04-20.zip.1’\n",
            "\n",
            "p.1                  52%[=========>          ]  88.66M  3.32MB/s    eta 26s    ^C\n",
            "Archive:  stanford-ner-2015-04-20.zip\n",
            "replace stanford-ner-2015-04-20/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSfCCO9PKQ27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "52cfdd4f-060c-4db0-aab7-d7e538222a8c"
      },
      "source": [
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "jar = \"stanford-ner-2015-04-20/stanford-ner-3.5.2.jar\"\n",
        "model = \"stanford-ner-2015-04-20/classifiers/\" \n",
        "st_3class = StanfordNERTagger(model + \"english.all.3class.distsim.crf.ser.gz\", jar, encoding='utf8') \n",
        "st_4class = StanfordNERTagger(model + \"english.conll.4class.distsim.crf.ser.gz\", jar, encoding='utf8') \n",
        "st_7class = StanfordNERTagger(model + \"english.muc.7class.distsim.crf.ser.gz\", jar, encoding='utf8') "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  '-tokenizerFactory',\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  '-tokenizerFactory',\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  '-tokenizerFactory',\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYow2ZnRKURv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stanford_ner(document,model):\n",
        "  if model == 1:\n",
        "    return [(entity,tag) for entity,tag in st_3class.tag(document.split()) if tag != \"O\"]\n",
        "  elif model == 2:\n",
        "    return [(entity,tag) for entity,tag in st_4class.tag(document.split()) if tag != \"O\"]\n",
        "  elif model == 3:\n",
        "    return [(entity,tag) for entity,tag in st_7class.tag(document.split()) if tag != \"O\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3tqJYjGKaaP",
        "colab_type": "code",
        "outputId": "6ced6ff0-b812-4a71-dc11-14a15d92a434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "stanford_ner(example_document,model=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hyundai', 'ORGANIZATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkPAFGdEOMrl",
        "colab_type": "code",
        "outputId": "7af9dc71-0807-448d-f89e-d972c5bdc75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "stanford_ner(example_document,model=2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Apollo', 'ORGANIZATION'),\n",
              " ('Project', 'ORGANIZATION'),\n",
              " ('Daimler', 'ORGANIZATION'),\n",
              " ('Hyundai', 'ORGANIZATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12cZITULOQ6u",
        "colab_type": "code",
        "outputId": "dce846b3-174e-48e0-c472-a99a12abc11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "stanford_ner(example_document,model=3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Apollo', 'ORGANIZATION'),\n",
              " ('Project', 'ORGANIZATION'),\n",
              " ('Daimler', 'ORGANIZATION'),\n",
              " ('Hyundai', 'ORGANIZATION'),\n",
              " ('Honda.', 'LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k7BvEX_t-RL",
        "colab_type": "text"
      },
      "source": [
        "# Allen NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojRC5XLQu8Ra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3215
        },
        "outputId": "366e6ba8-e6ea-48dc-da4a-b7634e297e2c"
      },
      "source": [
        "!pip3 install allennlp\n",
        "from allennlp.predictors import Predictor\n",
        "al = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/c8/10342a6068a8d156a5947e03c95525d559e71ad62de0f2585ab922e14533/allennlp-0.8.3-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.6.2)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Collecting tensorboardX>=1.2 (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.14.5)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\" (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dc/3abd3971869a741d7acdba166d71d4f9366b6b53028dfd56f95de356af0f/jsonnet-0.12.1.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Collecting parsimonious>=0.8.0 (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.3)\n",
            "Collecting responses>=0.7 (from allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n",
            "Collecting moto>=1.3.4 (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/35/f3dc85fa8fa2541b77849459363bb0d6e02bd44ba05afbd3ee3e035a6b14/moto-1.3.8-py2.py3-none-any.whl (580kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 43.8MB/s \n",
            "\u001b[?25hCollecting flaky (from allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\n",
            "Collecting flask-cors>=3.0.7 (from allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.4)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.23.4)\n",
            "Collecting ftfy (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.138)\n",
            "Collecting word2number>=1.1 (from allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.1.post2)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.6)\n",
            "Requirement already satisfied: spacy<2.2,>=2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.0.18)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.19.1)\n",
            "Collecting unidecode (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 48.3MB/s \n",
            "\u001b[?25hCollecting conllu==0.11 (from allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n",
            "Collecting numpydoc>=0.8.0 (from allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.19.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting awscli>=1.11.91 (from allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/55/171e17763cebb2ac329576ea322b3c9ffad303e409a2b8f0df39396170f8/awscli-1.16.151-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2018.1.10)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Collecting jsondiff==1.1.2 (from moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/0c/ddb17571e061c655871ccbf76cdada55a31569327d21517de779d4887241/jsondiff-1.1.2.tar.gz\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (0.15.2)\n",
            "Collecting xmltodict (from moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Collecting docker>=2.5.1 (from moto>=1.3.4->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/68/c3afca1a5aa8d2997ec3b8ee822a4d752cf85907b321f07ea86888545152/docker-3.7.2-py2.py3-none-any.whl (134kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 44.6MB/s \n",
            "\u001b[?25hCollecting aws-xray-sdk!=0.96,>=0.93 (from moto>=1.3.4->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f2/79f7918f4ddeec525742ddd4607abe4a82a29a6bc4c7e297995f59a18965/aws_xray_sdk-2.4.2-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto>=2.36.0 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.49.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (3.13)\n",
            "Collecting python-jose<4.0.0 (from moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/96/da/c0dcc5e7a98a53440b8db3cf9771345fa696754f79e8734ea59123f7d734/python_jose-3.0.1-py2.py3-none-any.whl\n",
            "Collecting cfn-lint (from moto>=1.3.4->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/82/f3c539fb6db5776b49138a8d9212a99313172d701b11e05824d224590483/cfn_lint-0.19.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.6.1)\n",
            "Requirement already satisfied: botocore>=1.12.86 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (1.12.138)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.7)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.10.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (2.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (0.2.9)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (6.12.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (1.35)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.23)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (7.0.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (39.1.0)\n",
            "Collecting colorama<=0.3.9,>=0.2.5 (from awscli>=1.11.91->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n",
            "Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.3MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.32.0 (from docker>=2.5.1->moto>=1.3.4->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 52.9MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from docker>=2.5.1->moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting jsonpickle (from aws-xray-sdk!=0.96,>=0.93->moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from aws-xray-sdk!=0.96,>=0.93->moto>=1.3.4->allennlp) (1.10.11)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from aws-xray-sdk!=0.96,>=0.93->moto>=1.3.4->allennlp) (0.16.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock->moto>=1.3.4->allennlp) (5.2.0)\n",
            "Collecting ecdsa<1.0 (from python-jose<4.0.0->moto>=1.3.4->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/a8/8aa68e70959e1287da9154e5164bb8bd5dd7025e41ae54e8d177b8d165c9/ecdsa-0.13.2-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 25.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema~=2.6 in /usr/local/lib/python3.6/dist-packages (from cfn-lint->moto>=1.3.4->allennlp) (2.6.0)\n",
            "Collecting jsonpatch (from cfn-lint->moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/d50d526ae2218b765ddbdb2dda14d65e19f501ce07410b375bc43ad20b7a/jsonpatch-1.23-py2.py3-none-any.whl\n",
            "Collecting aws-sam-translator>=1.10.0 (from cfn-lint->moto>=1.3.4->allennlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/dd/3f9c13d6454c4e59b71faacd19d7041e6d6becc76a8390aa2587f425df83/aws-sam-translator-1.11.0.tar.gz (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 33.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: asn1crypto>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (0.24.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (1.12.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->moto>=1.3.4->allennlp) (1.1.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (0.4.3.2)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (0.9.0.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.6.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->cfn-lint->moto>=1.3.4->allennlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3.0->moto>=1.3.4->allennlp) (2.19)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (0.9.0)\n",
            "Building wheels for collected packages: jsonnet, parsimonious, word2number, numpydoc, jsondiff, aws-sam-translator\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/47/51/a178b15274ed0db775a1ae9c799ce31e511609c3ab75a7dec5\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n",
            "  Building wheel for jsondiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/5f/86/11c6b72b064888e80b98bfcbcdaf2a83517a8cf8f2bb2a3227\n",
            "  Building wheel for aws-sam-translator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/39/44/8528735e5e1989a5b19b4e2230d63e92847903cee1ab94fe6e\n",
            "Successfully built jsonnet parsimonious word2number numpydoc jsondiff aws-sam-translator\n",
            "\u001b[31mERROR: deeppavlov 0.2.0 has requirement flask-cors==3.0.6, but you'll have flask-cors 3.0.7 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: deeppavlov 0.2.0 has requirement nltk==3.2.5, but you'll have nltk 3.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awscli 1.16.151 has requirement botocore==1.12.141, but you'll have botocore 1.12.138 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboardX, jsonnet, parsimonious, responses, jsondiff, xmltodict, websocket-client, docker-pycreds, docker, jsonpickle, aws-xray-sdk, ecdsa, rsa, python-jose, jsonpointer, jsonpatch, aws-sam-translator, cfn-lint, moto, flaky, flask-cors, ftfy, word2number, unidecode, conllu, numpydoc, colorama, awscli, allennlp\n",
            "  Found existing installation: rsa 4.0\n",
            "    Uninstalling rsa-4.0:\n",
            "      Successfully uninstalled rsa-4.0\n",
            "  Found existing installation: Flask-Cors 3.0.6\n",
            "    Uninstalling Flask-Cors-3.0.6:\n",
            "      Successfully uninstalled Flask-Cors-3.0.6\n",
            "Successfully installed allennlp-0.8.3 aws-sam-translator-1.11.0 aws-xray-sdk-2.4.2 awscli-1.16.151 cfn-lint-0.19.1 colorama-0.3.9 conllu-0.11 docker-3.7.2 docker-pycreds-0.4.0 ecdsa-0.13.2 flaky-3.5.3 flask-cors-3.0.7 ftfy-5.5.1 jsondiff-1.1.2 jsonnet-0.12.1 jsonpatch-1.23 jsonpickle-1.1 jsonpointer-2.0 moto-1.3.8 numpydoc-0.9.1 parsimonious-0.8.1 python-jose-3.0.1 responses-0.10.6 rsa-3.4.2 tensorboardX-1.6 unidecode-1.0.23 websocket-client-0.56.0 word2number-1.1 xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "rsa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 724601837/724601837 [00:52<00:00, 13728259.04B/s]\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_characters_indexer.py:51: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5hHwi5puQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_results(allen_results):\n",
        "  ents = set()\n",
        "  for word, tag in zip(allen_results[\"words\"], allen_results[\"tags\"]):\n",
        "    if tag != \"O\":\n",
        "      ent_position, ent_type = tag.split(\"-\")\n",
        "      if ent_position == \"U\":\n",
        "        ents.add((word,ent_type))\n",
        "      else:\n",
        "        if ent_position == \"B\":\n",
        "          w = word\n",
        "        elif ent_position == \"I\":\n",
        "          w += \" \" + word\n",
        "        elif ent_position == \"L\":\n",
        "          w += \" \" + word\n",
        "          ents.add((w,ent_type))\n",
        "  return ents\n",
        "\n",
        "def allennlp_ner(document):\n",
        "  return convert_results(al.predict(sentence=document))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBSuqZ9Oq-XT",
        "colab_type": "code",
        "outputId": "0da10ab0-4afb-483c-baa1-7fe5cf9d3895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "allennlp_ner(example_document)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('2018', 'DATE'),\n",
              " ('Apollo Project', 'ORG'),\n",
              " ('BYD', 'ORG'),\n",
              " ('Baidu', 'ORG'),\n",
              " ('Daimler AG', 'ORG'),\n",
              " ('Dongfeng', 'ORG'),\n",
              " ('Ford', 'ORG'),\n",
              " ('Grab', 'ORG'),\n",
              " ('Honda', 'ORG'),\n",
              " ('Hyundai', 'ORG'),\n",
              " ('Intel', 'ORG'),\n",
              " ('Microsoft', 'ORG'),\n",
              " ('Nvidia', 'ORG'),\n",
              " ('ZTE', 'ORG'),\n",
              " ('one', 'CARDINAL'),\n",
              " ('over 100', 'CARDINAL')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2uvc2hb1zrI",
        "colab_type": "text"
      },
      "source": [
        "# Polyglot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ixzM5Kn12Ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "aa87b779-5c65-4ffd-efc7-b9754c37f1d7"
      },
      "source": [
        "!pip3 install -U git+https://github.com/aboSamoor/polyglot.git@master\n",
        "!polyglot download embeddings2.en ner2.en\n",
        "from polyglot.text import Text"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/aboSamoor/polyglot.git@master\n",
            "  Cloning https://github.com/aboSamoor/polyglot.git (to revision master) to /tmp/pip-req-build-2wnozxsr\n",
            "  Running command git clone -q https://github.com/aboSamoor/polyglot.git /tmp/pip-req-build-2wnozxsr\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from polyglot==16.7.4) (1.14.5)\n",
            "Collecting futures>=2.1.6 (from polyglot==16.7.4)\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/26/b61e3a4eb50653e8a7339d84eeaa46d1e93b92951978873c220ae64d0733/futures-3.1.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from polyglot==16.7.4) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from polyglot==16.7.4) (0.33.1)\n",
            "Collecting pycld2>=0.3 (from polyglot==16.7.4)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/77/8525fe5f147bf2819c7c9942c717c4a79b83f8003da1a3847759fb560909/pycld2-0.31.tar.gz (14.3MB)\n",
            "\u001b[K     |████████████████████████████████| 14.3MB 34.5MB/s \n",
            "\u001b[?25hCollecting PyICU>=1.8 (from polyglot==16.7.4)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/35/211ffb949c68e688ade7d40426de030a24eaec4b6c45330eeb9c0285f43a/PyICU-2.3.1.tar.gz (214kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 49.4MB/s \n",
            "\u001b[?25hCollecting morfessor>=2.0.2a1 (from polyglot==16.7.4)\n",
            "  Downloading https://files.pythonhosted.org/packages/62/4d/1416982d31175e5053b8a0ae91b3e2761077f88d7a8071c7051a302299eb/Morfessor-2.0.4.tar.gz\n",
            "Building wheels for collected packages: polyglot, futures, pycld2, PyICU, morfessor\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nr0lv35n/wheels/42/d9/73/345c7ae8554299ff8b31635d64eb8455fd591385fa734cdbef\n",
            "  Building wheel for futures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f9/c7/4fbf1faa6038faf183f6e3ea61f17a5f7eea5ab9a1dd7753fd\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/44/44/ec4c5e25e095f02aa0e63ef2bf0cc8badda5877330ffa5fbe4\n",
            "  Building wheel for PyICU (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/45/7e/ccee9f1fe52787595e92641b5645cdf2cb40096749b39b4422\n",
            "  Building wheel for morfessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/74/e2/92a807d8662f5a0df908ba20887f8ad02bf1b130d3939b65b7\n",
            "Successfully built polyglot futures pycld2 PyICU morfessor\n",
            "Installing collected packages: futures, pycld2, PyICU, morfessor, polyglot\n",
            "Successfully installed PyICU-2.3.1 futures-3.1.1 morfessor-2.0.4 polyglot-16.7.4 pycld2-0.31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "concurrent"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package embeddings2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package ner2.en to /root/polyglot_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzUrNQKk2X7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def polyglot_ner(document):\n",
        "  return {(' '.join(entity),entity.tag.split('-')[-1]) for entity in Text(document).entities}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC9e3KFB3T93",
        "colab_type": "code",
        "outputId": "763599ca-1f8d-4c63-966c-a0ad1e100be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "polyglot_ner(example_document)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Daimler AG', 'ORG'),\n",
              " ('Honda', 'ORG'),\n",
              " ('Hyundai', 'ORG'),\n",
              " ('Intel', 'ORG'),\n",
              " ('Microsoft', 'ORG'),\n",
              " ('Nvidia', 'ORG')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}